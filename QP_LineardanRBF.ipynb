{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai X:\n",
      "[[1.472 0.845 0.845 ... 0.    0.    0.   ]\n",
      " [1.84  0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.    0.    ... 0.845 0.845 0.845]]\n",
      "==================\n",
      "\n",
      "Nilai Y:\n",
      "[ 1.  1. -1. -1. -1. -1.]\n",
      "==================\n",
      "\n",
      "Hitung Kernel Linear\n",
      "Banyak Array a =  6\n",
      "6\n",
      "==================\n",
      "\n",
      "Hasil Matriks Kernel Linear\n",
      "[[5.34824430e+01 3.38561600e+00 0.00000000e+00 4.06272000e-01\n",
      "  1.78056000e-01 8.52640000e-02]\n",
      " [3.38561600e+00 3.70816690e+01 2.95936000e-01 0.00000000e+00\n",
      "  4.26320000e-02 8.52640000e-02]\n",
      " [0.00000000e+00 2.95936000e-01 6.44374240e+01 4.73497600e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.06272000e-01 0.00000000e+00 4.73497600e+00 1.28073487e+02\n",
      "  6.77120000e-01 2.70848000e-01]\n",
      " [1.78056000e-01 4.26320000e-02 0.00000000e+00 6.77120000e-01\n",
      "  4.82749120e+01 1.00564560e+01]\n",
      " [8.52640000e-02 8.52640000e-02 0.00000000e+00 2.70848000e-01\n",
      "  1.00564560e+01 5.74188940e+01]]\n",
      "==================\n",
      "\n",
      "Append Array Pembulatan K\n",
      "[17, 8, 8, 8, 19, 8, 9, 19, 20, 19, 19, 9, 18, 8, 18, 10, 18, 8, 8, 20, 18, 9, 18, 19, 19, 8, 18, 18]\n",
      "==================\n",
      "\n",
      "Nilai Pembulatan Untuk K Sebanyak  6\n",
      "==================\n",
      "\n",
      "Kernel K Hasil Pembulatan\n",
      "53.482443\n",
      "3.385616\n",
      "0.0\n",
      "0.406272\n",
      "0.178056\n",
      "0.085264\n",
      "3.385616\n",
      "37.081669\n",
      "0.295936\n",
      "0.0\n",
      "0.042632\n",
      "0.085264\n",
      "0.0\n",
      "0.295936\n",
      "64.437424\n",
      "4.734976\n",
      "0.0\n",
      "0.0\n",
      "0.406272\n",
      "0.0\n",
      "4.734976\n",
      "128.073487\n",
      "0.67712\n",
      "0.270848\n",
      "0.178056\n",
      "0.042632\n",
      "0.0\n",
      "0.67712\n",
      "48.274912\n",
      "10.056456\n",
      "0.085264\n",
      "0.085264\n",
      "0.0\n",
      "0.270848\n",
      "10.056456\n",
      "57.418894\n",
      "==================\n",
      "\n",
      "Bagian Training Svm Lagrange Dualitas\n",
      "[ 1.00e+00  1.00e+00 -1.00e+00 -1.00e+00 -1.00e+00 -1.00e+00]\n",
      "\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.7287e-02 -1.4103e-01  9e-02  5e-18  1e+00\n",
      " 1: -4.7302e-02 -4.8342e-02  1e-03  6e-18  2e-02\n",
      " 2: -4.7303e-02 -4.7314e-02  1e-05  3e-18  2e-04\n",
      " 3: -4.7303e-02 -4.7303e-02  1e-07  1e-17  2e-06\n",
      " 4: -4.7303e-02 -4.7303e-02  1e-09  6e-18  2e-08\n",
      "Optimal solution found.\n",
      "==================\n",
      "\n",
      "Nilai Alpha 1-N Array\n",
      "[0.01901333 0.0282899  0.01308458 0.00622651 0.01545541 0.01253673]\n",
      "==================\n",
      "\n",
      "Nilai Alpha:\n",
      "[[0.01901333]\n",
      " [0.0282899 ]\n",
      " [0.01308458]\n",
      " [0.00622651]\n",
      " [0.01545541]\n",
      " [0.01253673]]\n",
      "Cek Panjang Karakter Nilai Alpha 1 20\n",
      "Cek Panjang Karakter Nilai Alpha 2 20\n",
      "Cek Panjang Karakter Nilai Alpha 3 20\n",
      "Cek Panjang Karakter Nilai Alpha 4 20\n",
      "Cek Panjang Karakter Nilai Alpha 5 20\n",
      "Cek Panjang Karakter Nilai Alpha 6 20\n",
      "==================\n",
      "\n",
      "Nilai Pembulatan Untuk Alpha Sebanyak  18\n",
      "Nilai Alpha 1 Adalah 0.019013331253987915\n",
      "0.019013331253987915\n",
      "Nilai Alpha 2 Adalah 0.028289902524057164\n",
      "-0.00927657127006925\n",
      "Nilai Alpha 3 Adalah 0.013084584937251093\n",
      "-0.02236115620732034\n",
      "Nilai Alpha 4 Adalah 0.006226509854231741\n",
      "-0.02858766606155208\n",
      "Nilai Alpha 5 Adalah 0.015455412975080204\n",
      "-0.044043079036632286\n",
      "Nilai Alpha 6 Adalah 0.012536726011482048\n",
      "-0.056579805048114336\n",
      "==================\n",
      "\n",
      "Jika Dimasukan Nilai Alpha ke Persamaan Adalah  -0.056579805048114336\n",
      "[ 1.10630763  1.10780861 -0.86424732 -0.86554216 -0.87180834 -0.8729248 ]\n",
      "==================\n",
      "\n",
      "Nilai Bias di bulatkan berdasarkan pembulatan alpha adalah  -61.33734426838822\n",
      "-61.33734426838822\n",
      "[[5.34824430e+01 3.38561600e+00 0.00000000e+00 4.06272000e-01\n",
      "  1.78056000e-01 8.52640000e-02]\n",
      " [3.38561600e+00 3.70816690e+01 2.95936000e-01 0.00000000e+00\n",
      "  4.26320000e-02 8.52640000e-02]\n",
      " [0.00000000e+00 2.95936000e-01 6.44374240e+01 4.73497600e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.06272000e-01 0.00000000e+00 4.73497600e+00 1.28073487e+02\n",
      "  6.77120000e-01 2.70848000e-01]\n",
      " [1.78056000e-01 4.26320000e-02 0.00000000e+00 6.77120000e-01\n",
      "  4.82749120e+01 1.00564560e+01]\n",
      " [8.52640000e-02 8.52640000e-02 0.00000000e+00 2.70848000e-01\n",
      "  1.00564560e+01 5.74188940e+01]]\n",
      "[ 1.10630763  1.10780861 -0.86424732 -0.86554216 -0.87180834 -0.8729248 ]\n",
      "[  62.33734427   44.45756727  -59.46035199 -115.32247947  -51.20686363\n",
      "  -58.93532454]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "from cvxopt import matrix, solvers\n",
    "#untuk rbf kernel\n",
    "from sklearn.metrics.pairwise import rbf_kernel, linear_kernel\n",
    "\n",
    "##ini X1\n",
    "xdata = ([[1.472, 0.845, 0.845, 0.845, 1.632, 4.225, 1.690, 0.845, 0.845, 0.544, 0.845, 0.845, 1.690, 0.845, 0.845, 0.845, 0.845, 0.544, 0.845, 0.845, 0.845, 0.845, 0.292, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.368, 1.690, 0.845, 1.690, 0.845, 0.845, 0.845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "[1.840, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.088, 0.0, 0.0, 0.0, 0.0, 0.292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.845, 1.690, 0.845, 0.845, 0.845, 0.845, 0.845, 2.535, 1.690, 0.845, 1.690, 0.845, 0.845, 0.845, 0.845, 0.845, 0.544, 1.690, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.535, 1.088, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 5.072, 0.845, 0.845, 0.845, 0.845, 1.088, 1.690, 0.845, 0.845, 0.845, 0.845, 0.845, 0.544, 0.845, 0.845, 1.690, 1.088, 0.845, 1.690, 1.690, 0.845, 0.845, 0.845, 0.544, 0.845, 0.845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.544, 0.0, 0.0, 0.0, 0.544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.632, 0.0, 0.0, 5.916, 7.606, 1.690, 0.845, 3.380, 0.368, 0.544, 0.845, 0.845, 0.544, 0.845, 0.845, 0.845, 1.690, 0.845, 0.845, 0.845, 0.845, 0.845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.845, 0.845, 0.845, 0.845, 0.845, 2.535, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 2.535, 0.845, 1.690, 1.690, 0.845, 2.176, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.845, 0.845, 0.845, 0.845, 0.845, 1.690, 1.690, 1.690, 0.845, 0.845, 1.690, 0.845, 0.845, 0.845, 0.845, 1.690, 0.845, 0.845, 1.690, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 0.845, 1.690, 0.845, 0.845, 0.845, 0.845]])\n",
    "ydata = ([1.0, 1.0, -1.0, -1.0, -1.0, -1.0])\n",
    "\n",
    "x = np.vstack(xdata)\n",
    "y = np.hstack(ydata)\n",
    "\n",
    "print(\"Nilai X:\")\n",
    "print(x)\n",
    "print(\"==================\")\n",
    "print()\n",
    "print(\"Nilai Y:\")\n",
    "print(y)\n",
    "print(\"==================\")\n",
    "print()\n",
    "\n",
    "#bagian awal hitung kernel rbf\n",
    "print (\"Hitung Kernel Linear\")\n",
    "print (\"Banyak Array a = \", len(x))\n",
    "n_data, n_fitur = x.shape\n",
    "print (n_data)\n",
    "\n",
    "# buat matriks nol X\n",
    "K = np.zeros((n_data, n_data))\n",
    "for i in range(n_data):\n",
    "    for j in range(n_data):\n",
    "        K[i,j] = linear_kernel(x[[i]], x[[j]])\n",
    "              \n",
    "        \n",
    "print(\"==================\")\n",
    "print()\n",
    "print (\"Hasil Matriks Kernel Linear\")\n",
    "print (K)\n",
    "#bagian akhir hitung kernel rbf\n",
    "print(\"==================\")\n",
    "print()\n",
    "\n",
    "# bagian awal pembulatan kernel rbf agar hasil persamaan lagrange-nya sesuai syarat\n",
    "simpan_kernel_pembulatan = []\n",
    "nkernelb,nkernelk = K.shape\n",
    "for banyakkerneli in range(nkernelb):\n",
    "    for banyakkernelj in range(nkernelk):\n",
    "        if len(str(K[banyakkerneli][banyakkernelj])) > 3:\n",
    "            simpan_kernel_pembulatan.append(len(str(K[banyakkerneli][banyakkernelj])))\n",
    "print (\"Append Array Pembulatan K\")\n",
    "print (simpan_kernel_pembulatan)\n",
    "print(\"==================\")\n",
    "print()\n",
    "\n",
    "min_data_k = min(simpan_kernel_pembulatan) - 2\n",
    "\n",
    "#kondisi cek apakah mengandung decimal atau tidak\n",
    "if min_data_k >=1:\n",
    "    nilaipembulatank = min_data_k\n",
    "else:\n",
    "    nilaipembulatank = 0\n",
    "print (\"Nilai Pembulatan Untuk K Sebanyak \", nilaipembulatank)\n",
    "print(\"==================\")\n",
    "print()\n",
    "\n",
    "#bagian awal buat ulang data K hasil pembulatan\n",
    "print (\"Kernel K Hasil Pembulatan\")\n",
    "for kernelbarui in range(nkernelb):\n",
    "    for kernelbaruj in range(nkernelk):\n",
    "        K[kernelbarui][kernelbaruj] = np.round(K[kernelbarui][kernelbaruj], nilaipembulatank)\n",
    "        \n",
    "        print (K[kernelbarui][kernelbaruj])\n",
    "#bagian akhir buat ulang data K hasil pembulatan\n",
    "\n",
    "# bagian akhir pembulatan kernel rbf agar hasil persamaan lagrange-nya sesuai syarat\n",
    "\n",
    "# bagian awal hitung lagrange dualitas lalu mendapatkan alpha dan bias\n",
    "print(\"==================\")\n",
    "print()\n",
    "print (\"Bagian Training Svm Lagrange Dualitas\")\n",
    "NUM = K.shape[0]\n",
    "DIM = K.shape[1]\n",
    "# dualitas lagrange dipecahkan\n",
    "\n",
    "# K dari perhitungan kernel RBF\n",
    "\n",
    "#bagian awal hitung alpha\n",
    "P = matrix(K)\n",
    "q = matrix(-np.ones((NUM, 1)))\n",
    "G = matrix(-np.eye(NUM))\n",
    "h = matrix(np.zeros(NUM))\n",
    "A = matrix(y.reshape(1, -1))\n",
    "print (A)\n",
    "b = matrix(np.zeros(1))\n",
    "#memunculkan solvers progress\n",
    "solvers.options['show_progress'] = True\n",
    "# bagian mencari nilai optimal lagrange dualitas dengan QP\n",
    "sol = solvers.qp(P, q, G, h, A, b)\n",
    "#didapatkan nilai alpha\n",
    "alphas = np.array(sol['x'])\n",
    "alpha1d = np.ravel(sol['x'])\n",
    "print(\"==================\")\n",
    "print()    \n",
    "print (\"Nilai Alpha 1-N Array\")\n",
    "print (alpha1d)\n",
    "#bagian akhir hitung alpha\n",
    "\n",
    "\n",
    "# untuk variabel cari min data panjang karakter\n",
    "min_data = []\n",
    "\n",
    "# get weights\n",
    "w = np.sum(alphas * y[:, None] * K, axis = 0)\n",
    "# get bias\n",
    "cond = (alphas > 0).reshape(-1)\n",
    "b = y[cond] - np.dot(K[cond], w)\n",
    "bias = b[0]\n",
    "\n",
    "print(\"==================\")\n",
    "print()\n",
    "print(\"Nilai Alpha:\")\n",
    "print(alphas)\n",
    "#untuk mengetahui berapa banyak alpha yang ada\n",
    "banyakdtalpha = len(alphas)\n",
    "#bagian awal menampilkan panjang kararkter nilai alpha\n",
    "##print (\"nilai alpha di numpy round\",np.round(alphas, 2))\n",
    "for tampili in range(banyakdtalpha):\n",
    "    print (\"Cek Panjang Karakter Nilai Alpha\", tampili+1,len(str(alphas[tampili][0])))\n",
    "#bagian akhir menampilkan panjang kararkter nilai alpha\n",
    "\n",
    "print(\"==================\")\n",
    "print()\n",
    "\n",
    "#bagian awal memasukan panjang karakter yang ada pada setiap alpha\n",
    "for banyaki in range(banyakdtalpha):\n",
    "    min_data.append(len(str(alphas[banyaki][0])))\n",
    "##print (\"min data length karakter alpha\", min(min_data))\n",
    "mulaisetelahkoma = min(min_data) - 2\n",
    "#kondisi cek apakah mengandung decimal atau tidak\n",
    "if mulaisetelahkoma >=1:\n",
    "    pdalpha = mulaisetelahkoma\n",
    "else:\n",
    "    pdalpha = 0\n",
    "#bagian akhir memasukan panjang karakter yang ada pada setiap alpha\n",
    "\n",
    "print (\"Nilai Pembulatan Untuk Alpha Sebanyak \", pdalpha)\n",
    "#bagian awal menampilkan dan mencoba memasukan nilai alpha kedalam syarat persamaan\n",
    "hasilpengurangan = 0\n",
    "for tampilai in range(banyakdtalpha):\n",
    "    print (\"Nilai Alpha\",tampilai+1,\"Adalah\",np.round(alphas[tampilai][0], pdalpha))\n",
    "    # jika data awal maka ditambahkan dulu, jika tidak maka dikurangkan\n",
    "    if tampilai == 0:\n",
    "        hasilpengurangan = np.round(hasilpengurangan, pdalpha) + np.round(alphas[tampilai][0], pdalpha)\n",
    "        print (np.round(hasilpengurangan, pdalpha))\n",
    "    else:\n",
    "        hasilpengurangan = np.round(hasilpengurangan, pdalpha) - np.round(alphas[tampilai][0], pdalpha)\n",
    "        print (np.round(hasilpengurangan, pdalpha))\n",
    "##    print (\"hasil pengurangan \",hasilpengurangan)\n",
    "#bagian akhir menampilkan dan mencoba memasukan nilai alpha kedalam syarat persamaan\n",
    "\n",
    "print(\"==================\")\n",
    "print()\n",
    "print (\"Jika Dimasukan Nilai Alpha ke Persamaan Adalah \", hasilpengurangan)\n",
    "##print(\"pake round biasa, masukkan ke persamaan jadi nilainya adalah \",np.round(alphas[0][0] - alphas[1][0] - alphas[2][0]))\n",
    "print(w)\n",
    "print(\"==================\")\n",
    "print()\n",
    "print (\"Nilai Bias di bulatkan berdasarkan pembulatan alpha adalah \", round(bias, pdalpha))\n",
    "print(bias)\n",
    "print(K[cond])\n",
    "print(w)\n",
    "print(np.dot(K[cond],w))\n",
    "# bagian akhir hitung lagrange dualitas lalu mendapatkan alpha dan bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
